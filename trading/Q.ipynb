{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 128\n",
    "# CNT_NEURONS = 128\n",
    "# LEARNING_EPS = 1e-2\n",
    "# LEARNING_RATE = 0.01\n",
    "# lr = theano.shared(np.array(LEARNING_RATE, dtype=np.float32))\n",
    "# CNT_EPOCHS = 200\n",
    "# CNT_ITERATIONS = 10\n",
    "# TIME_PERIOD = 60\n",
    "# EPS = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UtilFunctions:\n",
    "    \n",
    "    GRANULARITY = 100\n",
    "    \n",
    "    def calculate_sharpe_ratio_from_returns(returns):\n",
    "        numerator = np.mean(returns)\n",
    "        denominator = np.std(returns)\n",
    "        return numerator / (denominator + EPS)\n",
    "\n",
    "\n",
    "    def calculate_commission(count_bought, price, commission_rate=0.0006):\n",
    "        return np.abs(count_bought * price * commission_rate)\n",
    "\n",
    "\n",
    "    def calculate_return(count_before, count_now, price_before, price_now,\n",
    "                         granularity=1, commission_rate=0.0006):\n",
    "        ret = count_before * (price_now - price_before)\n",
    "        commission = calculate_commission(count_bought=count_now - count_before,\n",
    "                                          price=price_now,\n",
    "                                          commission_rate=commission_rate)\n",
    "        return (ret - commission) * granularity\n",
    "\n",
    "\n",
    "    def calculate_returns(paths, prices, granularity=1, commission_rate=0.0006):\n",
    "        returns = []\n",
    "        for time in range(1, prices.shape[1]):\n",
    "            ret = 0\n",
    "            for asset in range(0, prices.shape[0]):\n",
    "                ret += calculate_return(count_before=paths[asset][time - 1],\n",
    "                                        count_now=paths[asset][time],\n",
    "                                        price_before=prices[asset][time - 1],\n",
    "                                        price_now=prices[asset][time],\n",
    "                                        granularity=granularity,\n",
    "                                        commission_rate=commission_rate)\n",
    "            returns.append(ret)\n",
    "        return np.array(returns)\n",
    "\n",
    "\n",
    "    def calculate_sharpe_ratio(paths, prices, granularity=GRANULARITY,\n",
    "                               commission_rate=0.0006):\n",
    "        returns = calculate_returns(paths, prices, granularity, commission_rate)\n",
    "        return calculate_sharpe_ratio_from_returns(returns)\n",
    "\n",
    "    def build_returns_plot(returns, plot_name=None, filename=None):\n",
    "        cumulative_returns = np.cumsum(returns)\n",
    "        plt.plot(cumulative_returns)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Total return\")\n",
    "        if plot_name is not None:\n",
    "            plt.title(plot_name)\n",
    "        if filename is None:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class State:\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_state(data, prev_states):\n",
    "        return [data[-4], data[-3], data[-2], data[-1], prev_states[-1]]\n",
    "    \n",
    "    @staticmethod\n",
    "    def dims():\n",
    "        return 5\n",
    "    \n",
    "    @staticmethod\n",
    "    def data_req():\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NUM_ACTIONS = 3\n",
    "\n",
    "n_input = State.dims()\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 32\n",
    "n_hidden_3 = 16\n",
    "n_out = NUM_ACTIONS\n",
    "\n",
    "weights = {\n",
    "    'h1' : tf.Variable(tf.random_uniform([n_input, n_hidden_1], 0, 0.01)),\n",
    "    'h2' : tf.Variable(tf.random_uniform([n_hidden_1, n_hidden_2], 0, 0.01)),\n",
    "    'h3' : tf.Variable(tf.random_uniform([n_hidden_2, n_hidden_3], 0, 0.01)),\n",
    "    'out' : tf.Variable(tf.random_uniform([n_hidden_3, n_out], 0, 0.01))\n",
    "}\n",
    "\n",
    "\n",
    "def multilayer_model(x, weights):\n",
    "    layer_1 = tf.matmul(x, weights['h1'])\n",
    "    layer_2 = tf.nn.relu(tf.matmul(layer_1, weights['h2']))\n",
    "    layer_3 = tf.matmul(layer_2, weights['h3'])\n",
    "#     out_layer = tf.nn.softmax(tf.matmul(layer_3, weights['out']))\n",
    "    out_layer = tf.matmul(layer_3, weights['out'])\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "inputs = tf.placeholder(shape=[None, n_input], dtype=tf.float32)\n",
    "\n",
    "q_fn = multilayer_model(inputs, weights)\n",
    "\n",
    "next_q_fn = tf.placeholder(shape=[None, n_out], dtype=tf.float32)\n",
    "loss = tf.reduce_sum(tf.square(next_q_fn - q_fn))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def act(action, data, step, prev_states):\n",
    "    d_data = data[step] - data[step - 1]\n",
    "    d_state = action - 1 # -1, 0, +1\n",
    "    state = prev_states + d_state\n",
    "    reward = state * data[step] - prev_states[-1] * data[step - 1]\n",
    "    return state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discount_factor = 0.9\n",
    "exploration_rate = 0.1\n",
    "NUM_EPOCHS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_learning(sess, data, num_epochs=NUM_EPOCHS):\n",
    "    reward_per_epoch = []\n",
    "    final_state_per_epoch = []\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "        history = []\n",
    "        reward_all = 0\n",
    "        prev_states = [0]\n",
    "        steps = range(State.data_req(), len(data))\n",
    "        for step in steps:\n",
    "            state_vector = [State.get_state(data[:step], prev_states)]\n",
    "\n",
    "            q = sess.run(q_fn, feed_dict={inputs: state_vector})\n",
    "\n",
    "            # Exploration\n",
    "            if np.random.random() < exploration_rate:\n",
    "                action = [np.random.randint(0, NUM_ACTIONS)]\n",
    "            else:\n",
    "                action = np.argmax(q, axis=1)\n",
    "\n",
    "            state, reward = act(action[0], data, step, prev_states)\n",
    "\n",
    "            prev_states.append(state)\n",
    "\n",
    "            new_state_vector = [State.get_state(data[:step + 1], prev_states)]\n",
    "            new_q = sess.run(q_fn, feed_dict={inputs: new_state_vector})\n",
    "            max_new_q = np.max(new_q)\n",
    "\n",
    "            target_q = q\n",
    "            target_q[0][action[0]] = reward + discount_factor * max_new_q\n",
    "            \n",
    "            history.append([*state_vector, *target_q])\n",
    "        \n",
    "        state_vectors = [record[0] for record in history]\n",
    "        target_qs = [record[1] for record in history]\n",
    "        _ = sess.run([optimizer], feed_dict={inputs: state_vectors, next_q_fn: target_qs})\n",
    "\n",
    "\n",
    "        final_state_per_epoch.append(prev_states[-1])\n",
    "\n",
    "    return final_state_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "def read_data(data_path):\n",
    "    files = list(filter(lambda x : x.endswith('.csv'), listdir(data_path)))\n",
    "    prices_per_day = []\n",
    "    for i in range(len(files)):\n",
    "        input_data = pd.read_csv(data_path + files[i], sep=';')\n",
    "        day_prices = np.array(input_data['Open'])\n",
    "        prices_per_day.append(day_prices)\n",
    "    return np.array(prices_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_RUNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prices_per_day = read_data('data/train/')\n",
    "\n",
    "mean_income_per_day_per_run = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(NUM_RUNS):\n",
    "        mean_final_state_per_day = []\n",
    "        for prices in prices_per_day:\n",
    "            final_states_per_epoch = run_learning(sess, prices)\n",
    "            mean_final_state_per_day.append(np.mean(final_states_per_epoch))\n",
    "        mean_income_per_day_per_run.append(mean_final_state_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_income_per_day_per_run = np.array(mean_income_per_day_per_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_list = [(\"d_{}\".format(i), mean_income_per_day_per_run[:, i]) for i in range(len(prices_per_day))]\n",
    "results_dict = dict(results_list) \n",
    "df = pd.DataFrame.from_dict(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"mean\"] = np.mean(mean_income_per_day_per_run, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_0</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_10</th>\n",
       "      <th>d_11</th>\n",
       "      <th>d_12</th>\n",
       "      <th>d_13</th>\n",
       "      <th>d_14</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.129633</td>\n",
       "      <td>0.579300</td>\n",
       "      <td>0.206333</td>\n",
       "      <td>-0.018200</td>\n",
       "      <td>1.115733</td>\n",
       "      <td>2.111500</td>\n",
       "      <td>2.069200</td>\n",
       "      <td>2.128800</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.040233</td>\n",
       "      <td>0.528200</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>2.267467</td>\n",
       "      <td>1.146367</td>\n",
       "      <td>0.231233</td>\n",
       "      <td>0.880420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.275100</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>0.463600</td>\n",
       "      <td>0.049533</td>\n",
       "      <td>1.156800</td>\n",
       "      <td>-0.399633</td>\n",
       "      <td>2.247033</td>\n",
       "      <td>2.333133</td>\n",
       "      <td>0.225333</td>\n",
       "      <td>-0.068300</td>\n",
       "      <td>0.020433</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>2.669367</td>\n",
       "      <td>1.167367</td>\n",
       "      <td>0.214467</td>\n",
       "      <td>0.756820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.320967</td>\n",
       "      <td>0.682333</td>\n",
       "      <td>0.498367</td>\n",
       "      <td>-0.031233</td>\n",
       "      <td>1.255500</td>\n",
       "      <td>-2.238567</td>\n",
       "      <td>2.182033</td>\n",
       "      <td>-2.368700</td>\n",
       "      <td>-0.281367</td>\n",
       "      <td>0.248567</td>\n",
       "      <td>0.522067</td>\n",
       "      <td>-0.519467</td>\n",
       "      <td>-2.781633</td>\n",
       "      <td>1.166133</td>\n",
       "      <td>-0.273733</td>\n",
       "      <td>-0.150711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.310500</td>\n",
       "      <td>0.694833</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.028433</td>\n",
       "      <td>1.154267</td>\n",
       "      <td>-2.316333</td>\n",
       "      <td>2.170033</td>\n",
       "      <td>-2.325333</td>\n",
       "      <td>-0.250667</td>\n",
       "      <td>0.150633</td>\n",
       "      <td>0.497067</td>\n",
       "      <td>-0.451167</td>\n",
       "      <td>-2.753800</td>\n",
       "      <td>1.250700</td>\n",
       "      <td>-0.327833</td>\n",
       "      <td>-0.158538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.289333</td>\n",
       "      <td>0.629767</td>\n",
       "      <td>0.465333</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>1.132000</td>\n",
       "      <td>-2.287100</td>\n",
       "      <td>2.228367</td>\n",
       "      <td>-2.273667</td>\n",
       "      <td>-0.271433</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.567667</td>\n",
       "      <td>-0.460900</td>\n",
       "      <td>-2.691200</td>\n",
       "      <td>1.186133</td>\n",
       "      <td>-0.249133</td>\n",
       "      <td>-0.139320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.298867</td>\n",
       "      <td>0.664967</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>0.078267</td>\n",
       "      <td>1.199667</td>\n",
       "      <td>-2.281300</td>\n",
       "      <td>2.216567</td>\n",
       "      <td>-2.278200</td>\n",
       "      <td>-0.272667</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.552433</td>\n",
       "      <td>-0.429933</td>\n",
       "      <td>-2.799700</td>\n",
       "      <td>1.192933</td>\n",
       "      <td>-0.221933</td>\n",
       "      <td>-0.135091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.369067</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.450033</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>1.125200</td>\n",
       "      <td>-2.251600</td>\n",
       "      <td>2.283600</td>\n",
       "      <td>-2.275033</td>\n",
       "      <td>-0.191867</td>\n",
       "      <td>0.215867</td>\n",
       "      <td>0.546567</td>\n",
       "      <td>-0.475000</td>\n",
       "      <td>-2.822700</td>\n",
       "      <td>1.234667</td>\n",
       "      <td>-0.299367</td>\n",
       "      <td>-0.143051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.204267</td>\n",
       "      <td>0.647300</td>\n",
       "      <td>0.433067</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>1.155567</td>\n",
       "      <td>-2.234900</td>\n",
       "      <td>2.214200</td>\n",
       "      <td>-2.324500</td>\n",
       "      <td>-0.209500</td>\n",
       "      <td>0.224067</td>\n",
       "      <td>0.578833</td>\n",
       "      <td>-0.498867</td>\n",
       "      <td>-2.694833</td>\n",
       "      <td>1.231367</td>\n",
       "      <td>-0.222667</td>\n",
       "      <td>-0.124902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.340967</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>0.486767</td>\n",
       "      <td>-0.008400</td>\n",
       "      <td>1.185733</td>\n",
       "      <td>-2.257700</td>\n",
       "      <td>2.227133</td>\n",
       "      <td>-2.325500</td>\n",
       "      <td>-0.288300</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>0.493233</td>\n",
       "      <td>-0.505333</td>\n",
       "      <td>-2.720500</td>\n",
       "      <td>1.285433</td>\n",
       "      <td>-0.308333</td>\n",
       "      <td>-0.147613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.268133</td>\n",
       "      <td>0.609600</td>\n",
       "      <td>0.428033</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>1.182267</td>\n",
       "      <td>-2.244300</td>\n",
       "      <td>2.200067</td>\n",
       "      <td>-2.350067</td>\n",
       "      <td>-0.253300</td>\n",
       "      <td>0.249467</td>\n",
       "      <td>0.467933</td>\n",
       "      <td>-0.471933</td>\n",
       "      <td>-2.603800</td>\n",
       "      <td>1.214333</td>\n",
       "      <td>-0.195500</td>\n",
       "      <td>-0.131111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        d_0       d_1      d_10      d_11      d_12      d_13      d_14  \\\n",
       "0  0.129633  0.579300  0.206333 -0.018200  1.115733  2.111500  2.069200   \n",
       "1  0.275100  0.681400  0.463600  0.049533  1.156800 -0.399633  2.247033   \n",
       "2 -0.320967  0.682333  0.498367 -0.031233  1.255500 -2.238567  2.182033   \n",
       "3 -0.310500  0.694833  0.411600  0.028433  1.154267 -2.316333  2.170033   \n",
       "4 -0.289333  0.629767  0.465333  0.062300  1.132000 -2.287100  2.228367   \n",
       "5 -0.298867  0.664967  0.444400  0.078267  1.199667 -2.281300  2.216567   \n",
       "6 -0.369067  0.671233  0.450033  0.011700  1.125200 -2.251600  2.283600   \n",
       "7 -0.204267  0.647300  0.433067  0.031600  1.155567 -2.234900  2.214200   \n",
       "8 -0.340967  0.688867  0.486767 -0.008400  1.185733 -2.257700  2.227133   \n",
       "9 -0.268133  0.609600  0.428033  0.068667  1.182267 -2.244300  2.200067   \n",
       "\n",
       "        d_2       d_3       d_4       d_5       d_6       d_7       d_8  \\\n",
       "0  2.128800  0.189200  0.040233  0.528200  0.481300  2.267467  1.146367   \n",
       "1  2.333133  0.225333 -0.068300  0.020433  0.316667  2.669367  1.167367   \n",
       "2 -2.368700 -0.281367  0.248567  0.522067 -0.519467 -2.781633  1.166133   \n",
       "3 -2.325333 -0.250667  0.150633  0.497067 -0.451167 -2.753800  1.250700   \n",
       "4 -2.273667 -0.271433  0.161400  0.567667 -0.460900 -2.691200  1.186133   \n",
       "5 -2.278200 -0.272667  0.207000  0.552433 -0.429933 -2.799700  1.192933   \n",
       "6 -2.275033 -0.191867  0.215867  0.546567 -0.475000 -2.822700  1.234667   \n",
       "7 -2.324500 -0.209500  0.224067  0.578833 -0.498867 -2.694833  1.231367   \n",
       "8 -2.325500 -0.288300  0.173667  0.493233 -0.505333 -2.720500  1.285433   \n",
       "9 -2.350067 -0.253300  0.249467  0.467933 -0.471933 -2.603800  1.214333   \n",
       "\n",
       "        d_9      mean  \n",
       "0  0.231233  0.880420  \n",
       "1  0.214467  0.756820  \n",
       "2 -0.273733 -0.150711  \n",
       "3 -0.327833 -0.158538  \n",
       "4 -0.249133 -0.139320  \n",
       "5 -0.221933 -0.135091  \n",
       "6 -0.299367 -0.143051  \n",
       "7 -0.222667 -0.124902  \n",
       "8 -0.308333 -0.147613  \n",
       "9 -0.195500 -0.131111  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
